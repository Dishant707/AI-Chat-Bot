# System Architecture

## ğŸ—ï¸ How It Works

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         RAG System Flow                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Step 1: Web Scraping
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Website    â”‚
â”‚  Sitemap     â”‚  â”€â”€â”€â”€â”€â”€>  Crawl4AI  â”€â”€â”€â”€â”€â”€>  Markdown
â”‚  .txt File   â”‚             (Playwright)        Content
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Step 2: Processing & Storage
Markdown  â”€â”€>  Smart      â”€â”€>  Sentence      â”€â”€>  ChromaDB
Content        Chunking        Transformer        Vector DB
               (Headers)       (Embeddings)

Step 3: Query & Retrieval
User       â”€â”€>  Similarity  â”€â”€>  Top K       â”€â”€>  Context
Question        Search          Chunks           Retrieved

Step 4: Answer Generation
Context +   â”€â”€>  Google      â”€â”€>  Intelligent â”€â”€>  User
Question        Gemini           Answer           Response
                2.0 Flash
```

---

## ğŸ“¦ Component Breakdown

### 1ï¸âƒ£ **insert_docs.py** - The Crawler
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         insert_docs.py              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ â€¢ Detects URL type                  â”‚
â”‚ â€¢ Crawls with Crawl4AI              â”‚
â”‚ â€¢ Chunks markdown by headers        â”‚
â”‚ â€¢ Embeds with SentenceTransformer   â”‚
â”‚ â€¢ Stores in ChromaDB                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â”œâ”€> Regular Site: Recursive crawl
         â”œâ”€> Sitemap: Batch crawl all URLs
         â””â”€> .txt: Direct fetch & chunk
```

### 2ï¸âƒ£ **rag_agent.py** - The Brain
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚          rag_agent.py               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ â€¢ Receives user question            â”‚
â”‚ â€¢ Queries ChromaDB for context      â”‚
â”‚ â€¢ Constructs prompt with context    â”‚
â”‚ â€¢ Sends to Gemini 2.0 Flash         â”‚
â”‚ â€¢ Returns intelligent answer        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 3ï¸âƒ£ **streamlit_app.py** - The Interface
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚        streamlit_app.py             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ â€¢ Beautiful web UI                  â”‚
â”‚ â€¢ Chat interface                    â”‚
â”‚ â€¢ Streaming responses               â”‚
â”‚ â€¢ Config sidebar                    â”‚
â”‚ â€¢ Chat history                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 4ï¸âƒ£ **utils.py** - The Helper
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚            utils.py                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ â€¢ ChromaDB client management        â”‚
â”‚ â€¢ Collection operations             â”‚
â”‚ â€¢ Document insertion                â”‚
â”‚ â€¢ Query & retrieval                 â”‚
â”‚ â€¢ Result formatting                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ”„ Data Flow Example

### Example: User asks "What is Python?"

```
1. User Input
   â””â”€> "What is Python?"

2. ChromaDB Query
   â”œâ”€> Embed question with SentenceTransformer
   â”œâ”€> Search vector database
   â””â”€> Retrieve top 5 most relevant chunks

3. Retrieved Chunks (Example)
   â”œâ”€> Chunk 1: "Python is a high-level programming language..."
   â”œâ”€> Chunk 2: "Python features dynamic typing..."
   â”œâ”€> Chunk 3: "Python supports multiple paradigms..."
   â”œâ”€> Chunk 4: "Python has extensive standard library..."
   â””â”€> Chunk 5: "Python is widely used for web development..."

4. Prompt Construction
   â”œâ”€> System: "You are a helpful assistant..."
   â”œâ”€> Context: [All 5 chunks with metadata]
   â””â”€> Question: "What is Python?"

5. Gemini Processing
   â”œâ”€> Analyzes context + question
   â”œâ”€> Generates intelligent response
   â””â”€> Streams back to user

6. User Sees
   â””â”€> Comprehensive answer about Python based on crawled docs
```

---

## ğŸ§© Technology Stack

```
Frontend:
  â””â”€> Streamlit (Web UI)

Backend Processing:
  â”œâ”€> Python 3.11+
  â”œâ”€> Crawl4AI (Web scraping)
  â””â”€> Playwright (Browser automation)

AI/ML:
  â”œâ”€> Google Gemini 2.0 Flash (LLM)
  â””â”€> SentenceTransformers (Embeddings)

Data Storage:
  â””â”€> ChromaDB (Vector database)

Utilities:
  â”œâ”€> python-dotenv (Environment)
  â””â”€> asyncio (Async operations)
```

---

## ğŸ¯ Workflow Scenarios

### Scenario A: Crawl Documentation Site
```
python insert_docs.py https://docs.python.org/3/
    â”‚
    â”œâ”€> Starts at homepage
    â”œâ”€> Finds all internal links
    â”œâ”€> Crawls recursively (depth=3)
    â”œâ”€> Extracts markdown from each page
    â”œâ”€> Chunks by headers (max 1000 chars)
    â”œâ”€> Embeds each chunk
    â””â”€> Stores in ChromaDB collection 'docs'
```

### Scenario B: Query via Web UI
```
streamlit run streamlit_app.py
    â”‚
    â”œâ”€> Launches at http://localhost:8501
    â”œâ”€> User types question
    â”œâ”€> Retrieves context from ChromaDB
    â”œâ”€> Sends to Gemini with context
    â”œâ”€> Streams response back
    â””â”€> Displays in chat interface
```

### Scenario C: Command Line Query
```
python rag_agent.py "How do I use decorators?"
    â”‚
    â”œâ”€> Loads ChromaDB collection
    â”œâ”€> Searches for relevant chunks
    â”œâ”€> Constructs prompt
    â”œâ”€> Calls Gemini API
    â””â”€> Prints response to terminal
```

---

## ğŸ” Chunking Strategy Visual

```
Original Document:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ # Main Title (H1)                  â”‚
â”‚ Introduction paragraph...          â”‚
â”‚                                    â”‚
â”‚ ## Section 1 (H2)                  â”‚
â”‚ Content for section 1...           â”‚
â”‚                                    â”‚
â”‚ ### Subsection 1.1 (H3)            â”‚
â”‚ Details for subsection...          â”‚
â”‚                                    â”‚
â”‚ ## Section 2 (H2)                  â”‚
â”‚ Content for section 2...           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

After Smart Chunking:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Chunk 1 (< 1000 chars)             â”‚
â”‚ # Main Title                       â”‚
â”‚ Introduction paragraph...          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Chunk 2 (< 1000 chars)             â”‚
â”‚ ## Section 1                       â”‚
â”‚ Content for section 1...           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Chunk 3 (< 1000 chars)             â”‚
â”‚ ### Subsection 1.1                 â”‚
â”‚ Details for subsection...          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Chunk 4 (< 1000 chars)             â”‚
â”‚ ## Section 2                       â”‚
â”‚ Content for section 2...           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Benefits:
âœ“ Preserves document structure
âœ“ Maintains context within chunks
âœ“ Headers included for better understanding
âœ“ Optimal size for retrieval
```

---

## ğŸ’¾ ChromaDB Structure

```
chroma_db/
â””â”€> Collection: "docs"
    â”œâ”€> Document ID: "chunk-0"
    â”‚   â”œâ”€> Text: "# Python Tutorial\nPython is..."
    â”‚   â”œâ”€> Embedding: [0.123, -0.456, 0.789, ...]
    â”‚   â””â”€> Metadata:
    â”‚       â”œâ”€> source: "https://docs.python.org/tutorial"
    â”‚       â”œâ”€> headers: "# Python Tutorial"
    â”‚       â”œâ”€> char_count: 847
    â”‚       â””â”€> word_count: 142
    â”‚
    â”œâ”€> Document ID: "chunk-1"
    â”‚   â””â”€> ... (similar structure)
    â”‚
    â””â”€> ... (more chunks)
```

---

## ğŸš€ Performance Characteristics

### Crawling Speed
```
Small site (<50 pages):   ~2-5 minutes
Medium site (50-200):     ~10-20 minutes  
Large site (200-1000):    ~30-60 minutes
Massive site (1000+):     ~1-3 hours
```

### Query Speed
```
Embedding generation:     ~0.1-0.3 seconds
Vector search:            ~0.05-0.2 seconds
Gemini API call:          ~1-3 seconds (streaming)
Total response time:      ~1.5-4 seconds
```

### Resource Usage
```
Memory (crawling):        ~500MB - 2GB
Memory (querying):        ~200MB - 500MB
Disk (per 1000 chunks):   ~50-100MB (ChromaDB)
```

---

## ğŸ›ï¸ Configuration Matrix

| Parameter | Small Site | Medium Site | Large Site |
|-----------|------------|-------------|------------|
| max-depth | 2 | 3 | 4-5 |
| max-concurrent | 5 | 10 | 15-20 |
| chunk-size | 800 | 1000 | 1200 |
| n-results | 3-5 | 5-7 | 7-10 |

---

## ğŸ” Security Considerations

1. **API Keys**: Stored in .env (gitignored)
2. **Rate Limits**: Gemini has quota limits (monitor usage)
3. **Web Scraping**: Respect robots.txt and ToS
4. **Data Privacy**: Documents stored locally in ChromaDB

---

## ğŸ“Š Comparison Table

| Aspect | This Project | Original |
|--------|-------------|----------|
| LLM Provider | Google Gemini | OpenAI |
| Cost | Free tier + cheap | Paid only |
| Agent Framework | Direct API | Pydantic AI |
| Complexity | Simple | More complex |
| Dependencies | Fewer | More |
| Setup Time | 5 minutes | 10 minutes |
| Streaming | Native | Via framework |

---

This architecture provides a robust, scalable, and cost-effective RAG system! ğŸ‰
